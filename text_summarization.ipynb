{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e5f63d26addd46e78dadc1e662263841": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5110d680d72444e7961326f5c8b839f5",
              "IPY_MODEL_f1c992a328574d2ab3ae284c16ed9391",
              "IPY_MODEL_aae1a036e0f54cb1bba95fd4b5ef2e4f"
            ],
            "layout": "IPY_MODEL_bc6bed588391432b97e24f3ab7d47dd0"
          }
        },
        "5110d680d72444e7961326f5c8b839f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e090dbd9b64449ce91fec3147e8cead8",
            "placeholder": "​",
            "style": "IPY_MODEL_45761b98ebab43dcb815be9342a140a7",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "f1c992a328574d2ab3ae284c16ed9391": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57d83133b98046019ff0ebe4d09941b7",
            "max": 990446387,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13f825eef96c4bc887d55f16554a445c",
            "value": 990446387
          }
        },
        "aae1a036e0f54cb1bba95fd4b5ef2e4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_215d9697ef9b4dc4bc4b18851292df3a",
            "placeholder": "​",
            "style": "IPY_MODEL_a562849ede5a470ea56592afe88bb572",
            "value": " 990M/990M [00:36&lt;00:00, 39.6MB/s]"
          }
        },
        "bc6bed588391432b97e24f3ab7d47dd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e090dbd9b64449ce91fec3147e8cead8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45761b98ebab43dcb815be9342a140a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57d83133b98046019ff0ebe4d09941b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13f825eef96c4bc887d55f16554a445c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "215d9697ef9b4dc4bc4b18851292df3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a562849ede5a470ea56592afe88bb572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0e3e003c2da4c88900ed8fdf21169c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_138d2ce4fed044719a935e997539b6c6",
              "IPY_MODEL_8182386ed7404abeba5dfc6f0a0efaa5",
              "IPY_MODEL_ae524bce16354501b46333bcc8379a24"
            ],
            "layout": "IPY_MODEL_bb1fd5283d1d4cc58d10387a420e1711"
          }
        },
        "138d2ce4fed044719a935e997539b6c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e33444f64a54bc88b168b52c6fba1cd",
            "placeholder": "​",
            "style": "IPY_MODEL_c1865b77537840289969d46f62c135ce",
            "value": "model.safetensors: 100%"
          }
        },
        "8182386ed7404abeba5dfc6f0a0efaa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08e08e1466b64a0c866da66fe3dcad33",
            "max": 990386200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3611c004c554804a7877da4d410b6e6",
            "value": 990386200
          }
        },
        "ae524bce16354501b46333bcc8379a24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04bbf8b61c9f484dab07b6225a3b30e2",
            "placeholder": "​",
            "style": "IPY_MODEL_df54c8e812444e6894f8ace84620067c",
            "value": " 990M/990M [00:27&lt;00:00, 76.3MB/s]"
          }
        },
        "bb1fd5283d1d4cc58d10387a420e1711": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e33444f64a54bc88b168b52c6fba1cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1865b77537840289969d46f62c135ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08e08e1466b64a0c866da66fe3dcad33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3611c004c554804a7877da4d410b6e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04bbf8b61c9f484dab07b6225a3b30e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df54c8e812444e6894f8ace84620067c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ca0942a84024a6a8ca03fe3abc1a5d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e568acdf486e4e72b16f7fbca6d60d73",
              "IPY_MODEL_028ee4443c9c4972b815a93868eb24d2",
              "IPY_MODEL_0bb4515eea5447f285f2d98e011b9977"
            ],
            "layout": "IPY_MODEL_4a6cf1f0448b452986e471e1d8cfcb5b"
          }
        },
        "e568acdf486e4e72b16f7fbca6d60d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f646cdae038c4cc0ac049270cd4d71c5",
            "placeholder": "​",
            "style": "IPY_MODEL_16877507339e40cea0a03e14b3b05cac",
            "value": "generation_config.json: 100%"
          }
        },
        "028ee4443c9c4972b815a93868eb24d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06b3f3299ab4470a86460d1139a52e53",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d0140ec347b4a039119c519280c77b2",
            "value": 147
          }
        },
        "0bb4515eea5447f285f2d98e011b9977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_329e7b75bc1f423cb75cb97439b72d44",
            "placeholder": "​",
            "style": "IPY_MODEL_153b4e710a794012864a61c551de4c6b",
            "value": " 147/147 [00:00&lt;00:00, 1.05kB/s]"
          }
        },
        "4a6cf1f0448b452986e471e1d8cfcb5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f646cdae038c4cc0ac049270cd4d71c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16877507339e40cea0a03e14b3b05cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06b3f3299ab4470a86460d1139a52e53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d0140ec347b4a039119c519280c77b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "329e7b75bc1f423cb75cb97439b72d44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "153b4e710a794012864a61c551de4c6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73151843e78b41d0b6945829f71c2037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86e3ee0f25f946fd8f3edca9d1af9de5",
              "IPY_MODEL_bba023e2b3c146558b727354b7283598",
              "IPY_MODEL_2ae0d33ad9a94e71913e81e8e50546f4"
            ],
            "layout": "IPY_MODEL_7744e23110fd48ddb6e2643c6c1e6687"
          }
        },
        "86e3ee0f25f946fd8f3edca9d1af9de5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_327a3e3dfc3e457dbb8a3f3c3c445588",
            "placeholder": "​",
            "style": "IPY_MODEL_e45feae2ee5848e5bc2f34f46376f023",
            "value": "spiece.model: 100%"
          }
        },
        "bba023e2b3c146558b727354b7283598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d11647b58b74db38c44b68ad27bb3d2",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2ea6f93b4a04ab9827a138903f43370",
            "value": 791656
          }
        },
        "2ae0d33ad9a94e71913e81e8e50546f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f32e78820b8c42a6954ab8e5ce3a88ce",
            "placeholder": "​",
            "style": "IPY_MODEL_a3735721c1a7454f8e8bcdfca4db05dc",
            "value": " 792k/792k [00:00&lt;00:00, 5.29MB/s]"
          }
        },
        "7744e23110fd48ddb6e2643c6c1e6687": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "327a3e3dfc3e457dbb8a3f3c3c445588": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e45feae2ee5848e5bc2f34f46376f023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d11647b58b74db38c44b68ad27bb3d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2ea6f93b4a04ab9827a138903f43370": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f32e78820b8c42a6954ab8e5ce3a88ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3735721c1a7454f8e8bcdfca4db05dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1 AI-Based News Summarization"
      ],
      "metadata": {
        "id": "qEHv4btd0vI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall newspaper3k lxml\n",
        "# !pip install lxml_html_clean\n",
        "# !pip install newspaper3k"
      ],
      "metadata": {
        "id": "IbJWA9E7zjzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m819mbaAzcPo",
        "outputId": "a38610b5-06cb-4e3d-dc35-501c517af348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " IT Ministry examining issue of Grok using Hindi slang, abuses; in touch with social media platform X over the recent incident of AI chatbot Grok . Enforcement Directorate (ED) registered a total of 193 cases against politicians over the last 10 years and secured conviction in two of those, the government has informed Parliament .\n"
          ]
        }
      ],
      "source": [
        "from newspaper import Article\n",
        "from transformers import pipeline\n",
        "\n",
        "url = 'https://www.thehindu.com/news/the-hindu-morning-digest-march-20-2025/article69351767.ece'\n",
        "article = Article(url)\n",
        "article.download()\n",
        "article.parse()\n",
        "\n",
        "# print(article.text)\n",
        "\n",
        "summarizer = pipeline('summarization')\n",
        "summary = summarizer(article.text, max_length = 100, min_length = 20, do_sample = False)\n",
        "\n",
        "print(summary[0]['summary_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Pdf Summarizer"
      ],
      "metadata": {
        "id": "gS0GLwUe2IX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "XSPMEV4b3E4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "from transformers import pipeline, BartTokenizer\n",
        "\n",
        "# Load and extract text from pdf\n",
        "def extract_text(pdf_path):\n",
        "  text = ''\n",
        "  with open(pdf_path, 'rb') as file:\n",
        "    reader = PyPDF2.PdfReader(file)\n",
        "    for page in reader.pages:\n",
        "      text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "pdf_text = extract_text('ML_coursera_sup_proj.pdf')\n",
        "\n",
        "# Summarization\n",
        "summarizer = pipeline('summarization')\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "\n",
        "tokens = tokenizer.encode(pdf_text, return_tensors='pt')\n",
        "\n",
        "max_length = 1024\n",
        "if tokens.shape[1] > max_length:\n",
        "  tokens = tokens[:, :max_length]\n",
        "  pdf_text = tokenizer.decode(tokens[0], skip_special_tokens=True)\n",
        "\n",
        "print(pdf_text)\n",
        "\n",
        "summary = summarizer(pdf_text, max_length = 250, min_length = 50, do_sample = False)\n",
        "\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "2ohi8JtlzgjE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f044aef8-23e2-4e92-9af6-cc11b6d0485c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression Project Report \n",
            "Main Objective of the Analysis\n",
            "The main objective of this analysis is to predict housing prices using linear regression models. The \n",
            "focus is on creating an interpretable model that explains key factors driving housing prices. This \n",
            "analysis aims to provide actionable insights and recommendations for stakeholders based on the \n",
            "predictive power of the models.\n",
            "Dataset Description\n",
            "The dataset used for this analysis is the Ames Housing Dataset , a publicly available dataset \n",
            "containing comprehensive details about residential homes in Ames, Iowa. The dataset includes:\n",
            "•Target Variable: SalePrice, representing the sale price of the house.\n",
            "•Predictor Variables : Various numeric and categorical features such as LotArea, \n",
            "YearBuilt, OverallQual, etc., capturing the characteristics of the house and its \n",
            "surroundings.\n",
            "Dataset Overview:\n",
            "•Number of Rows: 2,930\n",
            "•Number of Features: 81\n",
            "•Numeric Features: 38\n",
            "•Categorical Features: 43\n",
            "Missing Data Handling:\n",
            "•Columns with a significant percentage of missing values were dropped.\n",
            "•Imputation techniques were applied for features with fewer missing values (e.g., mean \n",
            "imputation for numeric features).\n",
            "Data Exploration and Cleaning\n",
            "1.Correlation Analysis :\n",
            "•A heatmap was generated to identify highly correlated features.\n",
            "•The target variable SalePrice showed strong positive correlations with features \n",
            "like OverallQual (quality of the house) and GrLivArea (above-ground living \n",
            "area).\n",
            "2.Outlier Removal:\n",
            "•Outliers in highly correlated features were identified and removed to improve model \n",
            "performance.3.Feature Engineering :\n",
            "•Categorical variables were encoded using one-hot encoding.\n",
            "•Polynomial features were added to capture non-linear relationships.\n",
            "4.Data Splitting:\n",
            "•The dataset was split into 80% training and 20% testing subsets using random \n",
            "stratification.\n",
            "Model Training and Evaluation\n",
            "Three variations of linear regression models were trained and evaluated:\n",
            "1. Simple Linear Regression\n",
            "•A baseline model using only the most correlated predictor ( OverallQual).\n",
            "•Performance:\n",
            "•Mean Squared Error (MSE): 22,400\n",
            "•R-squared (R²): 0.68\n",
            "2. Polynomial Regression\n",
            "•Degree-2 polynomial features were added to capture non-linear relationships.\n",
            "•Performance:\n",
            "•MSE: 20,500\n",
            "•R²: 0.72\n",
            "3. Ridge Regression\n",
            "•A regularized linear regression model with L2 penalty to reduce overfitting.\n",
            "•Performance:\n",
            "•MSE: 19,800\n",
            "•R²: 0.74\n",
            "Recommended Model\n",
            "The Ridge Regression model was selected as the final model for this analysis. It provided the best \n",
            "balance between accuracy and model simplicity, effectively addressing multicollinearity and \n",
            "preventing overfitting.\n",
            "Model Coefficients:\n",
            "•The most significant predictors included OverallQual, GrLivArea, and \n",
            "GarageCars.•Regularization ensured that less important features had minimal impact on the model’s \n",
            "predictions.\n",
            "Key Findings and Insights\n",
            "1.Main Drivers of House Prices :\n",
            "•Houses with higher quality ( OverallQual) and larger living areas ( GrLivArea) \n",
            "command significantly higher prices.\n",
            "•The number of garage spaces ( GarageCars) also positively impacts house prices.\n",
            "2.Non-linear Relationships :\n",
            "•Polynomial features captured non-linear relationships, revealing that GrLivArea \n",
            "has diminishing returns on price after a certain threshold.\n",
            "3.Impact of Regularization :\n",
            "•Ridge Regression mitigated overfitting by reducing the impact of less significant \n",
            "features.\n",
            "Suggestions for Next Steps\n",
            "1.Data Enrichment:\n",
            "•Incorporate additional features such as neighborhood-level economic indicators or \n",
            "market trends.\n",
            "•Collect temporal data to account for seasonality in housing prices.\n",
            "2.Model Exploration :\n",
            "•Experiment with advanced models like Random Forest or Gradient Boosting to \n",
            "evaluate their predictive performance.\n",
            "•Investigate feature importance using SHAP values or permutation importance.\n",
            "3.Handling Categorical Variables :\n",
            "•Explore target encoding for high-cardinality categorical variables to enhance model \n",
            "performance.\n",
            "4.Improved Regularization :\n",
            "•Test Lasso Regression for feature selection and ElasticNet for combining L1 and L2 \n",
            "penalties.\n",
            "Conclusion\n",
            "This analysis successfully demonstrated the use of linear regression models to predict housing \n",
            "prices. The Ridge Regression model was chosen as the final model for its robustness and interpretability. Future analysis can leverage additional features and advanced modeling techniques \n",
            "to further improve predictions and insights\n",
            "[{'summary_text': ' The main objective of this analysis is to predict housing prices using linear regression models . The Ames Housing Dataset is a publicly available dataset containing comprehensive details about residential homes in Ames, Iowa . The Ridge Regression model was selected as the final model for this analysis .'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 Youtube Transcript Summarization"
      ],
      "metadata": {
        "id": "lSpjBp6drZWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube_transcript_api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLo4dpcVrgtc",
        "outputId": "c6dde3e3-6001-48fc-a1e4-10b0dd8ba2c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube_transcript_api\n",
            "  Downloading youtube_transcript_api-1.0.3-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube_transcript_api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube_transcript_api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (2025.1.31)\n",
            "Downloading youtube_transcript_api-1.0.3-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: youtube_transcript_api\n",
            "Successfully installed youtube_transcript_api-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "\n",
        "\n",
        "# Extract Youtube video Id seperately\n",
        "\n",
        "def extract_video_id(video_url):\n",
        "  parsed_text = urlparse(video_url)  # split the url in sub urls\n",
        "  # print(parsed_text.hostname, parsed_text)\n",
        "\n",
        "  if parsed_text.hostname in ['www.youtube.com', 'youtube.com', 'm.youtube.com']:\n",
        "    query = parse_qs(parsed_text.query)\n",
        "    # print(query)\n",
        "    if 'v' in query:\n",
        "      return query['v'][0]\n",
        "    elif 'youtu.be' in parsed_text.netloc:   # Handle Youtube shorts\n",
        "      return parsed_text.path[1:]\n",
        "  elif parsed_text.hostname == 'youtu.be':\n",
        "    return parsed_text.path[1:]\n",
        "  else:\n",
        "    return None\n",
        "\n",
        "\n",
        "# Get the transcript of the video and summarize the texts in it.\n",
        "\n",
        "def summarization(video_url):\n",
        "  video_id = extract_video_id(video_url)   # Extract video id from using function\n",
        "  if video_id:\n",
        "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "    transcript_text = ' '.join([entry['text'] for entry in transcript])\n",
        "    print(len(transcript_text))\n",
        "    print(transcript_text)\n",
        "\n",
        "\n",
        "    max_length = min(int(len(transcript_text) * 0.4), 1024)\n",
        "    min_length = min(int(len(transcript_text)*0.2), 512)\n",
        "    # max_length = 512\n",
        "    # min_length = 100\n",
        "    print( min_length, max_length)\n",
        "\n",
        "    model_name = 'google/long-t5-tglobal-base'\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "    inputs = tokenizer.encode(transcript_text, return_tensors='pt')\n",
        "\n",
        "\n",
        "    summarizer = pipeline('summarization', model=model, tokenizer=tokenizer)\n",
        "    summary = summarizer(transcript_text, max_length = max_length, min_length = min_length, do_sample= False)\n",
        "    print(summary[0]['summary_text'])\n",
        "    print(len(summary[0]['summary_text']))\n",
        "\n",
        "\n",
        "  else:\n",
        "    return \"Invalid URL\"\n",
        "\n",
        "\n",
        "video_url = 'https://youtu.be/eCDTp5h59hg?si=fdG03gNGkkixzXVJ'\n",
        "summarization(video_url)\n"
      ],
      "metadata": {
        "id": "Aqn27HaG3G3T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "outputId": "1389601d-aebf-4083-8278-4f6d03ed6d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RequestBlocked",
          "evalue": "\nCould not retrieve a transcript for the video https://www.youtube.com/watch?v=eCDTp5h59hg! This is most likely caused by:\n\nYouTube is blocking requests from your IP. This usually is due to one of the following reasons:\n- You have done too many requests and your IP has been blocked by YouTube\n- You are doing requests from an IP belonging to a cloud provider (like AWS, Google Cloud Platform, Azure, etc.). Unfortunately, most IPs from cloud providers are blocked by YouTube.\n\nThere are two things you can do to work around this:\n1. Use proxies to hide your IP address, as explained in the \"Working around IP bans\" section of the README (https://github.com/jdepoix/youtube-transcript-api?tab=readme-ov-file#working-around-ip-bans-requestblocked-or-ipblocked-exception).\n2. (NOT RECOMMENDED) If you authenticate your requests using cookies, you will be able to continue doing requests for a while. However, YouTube will eventually permanently ban the account that you have used to authenticate with! So only do this if you don't mind your account being banned!\n\nIf you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRequestBlocked\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-10a468c0cf4b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mvideo_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://youtu.be/eCDTp5h59hg?si=fdG03gNGkkixzXVJ'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0msummarization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-10a468c0cf4b>\u001b[0m in \u001b[0;36msummarization\u001b[0;34m(video_url)\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mvideo_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_video_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_url\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Extract video id from using function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvideo_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtranscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYouTubeTranscriptApi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transcript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mtranscript_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtranscript\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/youtube_transcript_api/_api.py\u001b[0m in \u001b[0;36mget_transcript\u001b[0;34m(cls, video_id, languages, proxies, cookies, preserve_formatting)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"`video_id` must be a string\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         return (\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_transcripts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcookies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mfind_transcript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreserve_formatting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreserve_formatting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/youtube_transcript_api/_api.py\u001b[0m in \u001b[0;36mlist_transcripts\u001b[0;34m(cls, video_id, proxies, cookies)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mcookie_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcookies\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcookies\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         )\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mytt_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/youtube_transcript_api/_api.py\u001b[0m in \u001b[0;36mlist\u001b[0;34m(self, video_id)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mMake\u001b[0m \u001b[0msure\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mthis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mactual\u001b[0m \u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNOT\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mURL\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;31m!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \"\"\"\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/youtube_transcript_api/_transcripts.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, video_id)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_http_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mvideo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_captions_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         )\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/youtube_transcript_api/_transcripts.py\u001b[0m in \u001b[0;36m_fetch_captions_json\u001b[0;34m(self, video_id, try_number)\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtry_number\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mretries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_captions_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_number\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtry_number\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_proxy_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proxy_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_captions_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/youtube_transcript_api/_transcripts.py\u001b[0m in \u001b[0;36m_fetch_captions_json\u001b[0;34m(self, video_id, try_number)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fetch_captions_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_number\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             return self._extract_captions_json(\n\u001b[0m\u001b[1;32m    358\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_video_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/youtube_transcript_api/_transcripts.py\u001b[0m in \u001b[0;36m_extract_captions_json\u001b[0;34m(self, html, video_id)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_playability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"playabilityStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         captions_json = video_data.get(\"captions\", {}).get(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/youtube_transcript_api/_transcripts.py\u001b[0m in \u001b[0;36m_assert_playability\u001b[0;34m(self, playability_status_data, video_id)\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mplayability_status\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_PlayabilityStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOGIN_REQUIRED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_PlayabilityFailedReason\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBOT_DETECTED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRequestBlocked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_PlayabilityFailedReason\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAGE_RESTRICTED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mAgeRestricted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRequestBlocked\u001b[0m: \nCould not retrieve a transcript for the video https://www.youtube.com/watch?v=eCDTp5h59hg! This is most likely caused by:\n\nYouTube is blocking requests from your IP. This usually is due to one of the following reasons:\n- You have done too many requests and your IP has been blocked by YouTube\n- You are doing requests from an IP belonging to a cloud provider (like AWS, Google Cloud Platform, Azure, etc.). Unfortunately, most IPs from cloud providers are blocked by YouTube.\n\nThere are two things you can do to work around this:\n1. Use proxies to hide your IP address, as explained in the \"Working around IP bans\" section of the README (https://github.com/jdepoix/youtube-transcript-api?tab=readme-ov-file#working-around-ip-bans-requestblocked-or-ipblocked-exception).\n2. (NOT RECOMMENDED) If you authenticate your requests using cookies, you will be able to continue doing requests for a while. However, YouTube will eventually permanently ban the account that you have used to authenticate with! So only do this if you don't mind your account being banned!\n\nIf you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oibA7LIvrWu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "e5f63d26addd46e78dadc1e662263841",
            "5110d680d72444e7961326f5c8b839f5",
            "f1c992a328574d2ab3ae284c16ed9391",
            "aae1a036e0f54cb1bba95fd4b5ef2e4f",
            "bc6bed588391432b97e24f3ab7d47dd0",
            "e090dbd9b64449ce91fec3147e8cead8",
            "45761b98ebab43dcb815be9342a140a7",
            "57d83133b98046019ff0ebe4d09941b7",
            "13f825eef96c4bc887d55f16554a445c",
            "215d9697ef9b4dc4bc4b18851292df3a",
            "a562849ede5a470ea56592afe88bb572",
            "a0e3e003c2da4c88900ed8fdf21169c7",
            "138d2ce4fed044719a935e997539b6c6",
            "8182386ed7404abeba5dfc6f0a0efaa5",
            "ae524bce16354501b46333bcc8379a24",
            "bb1fd5283d1d4cc58d10387a420e1711",
            "0e33444f64a54bc88b168b52c6fba1cd",
            "c1865b77537840289969d46f62c135ce",
            "08e08e1466b64a0c866da66fe3dcad33",
            "d3611c004c554804a7877da4d410b6e6",
            "04bbf8b61c9f484dab07b6225a3b30e2",
            "df54c8e812444e6894f8ace84620067c",
            "1ca0942a84024a6a8ca03fe3abc1a5d4",
            "e568acdf486e4e72b16f7fbca6d60d73",
            "028ee4443c9c4972b815a93868eb24d2",
            "0bb4515eea5447f285f2d98e011b9977",
            "4a6cf1f0448b452986e471e1d8cfcb5b",
            "f646cdae038c4cc0ac049270cd4d71c5",
            "16877507339e40cea0a03e14b3b05cac",
            "06b3f3299ab4470a86460d1139a52e53",
            "0d0140ec347b4a039119c519280c77b2",
            "329e7b75bc1f423cb75cb97439b72d44",
            "153b4e710a794012864a61c551de4c6b",
            "73151843e78b41d0b6945829f71c2037",
            "86e3ee0f25f946fd8f3edca9d1af9de5",
            "bba023e2b3c146558b727354b7283598",
            "2ae0d33ad9a94e71913e81e8e50546f4",
            "7744e23110fd48ddb6e2643c6c1e6687",
            "327a3e3dfc3e457dbb8a3f3c3c445588",
            "e45feae2ee5848e5bc2f34f46376f023",
            "2d11647b58b74db38c44b68ad27bb3d2",
            "d2ea6f93b4a04ab9827a138903f43370",
            "f32e78820b8c42a6954ab8e5ce3a88ce",
            "a3735721c1a7454f8e8bcdfca4db05dc"
          ]
        },
        "outputId": "847fc392-afc2-4713-f2cd-adb42cac012d",
        "id": "wJ-LvNNO7D_g"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi everyone welcome back to our channel in this video we will discuss some great computer vision projects without further Ado let's start with number 20 building a robotic arm that can pick up and sort objects is no easy task but Kai and his friends took on the challenge of developing their own automated system their goal to detect colored balls and sort them accurately using a budget friendly robotic manipulator they use the open manipulator x a lowcost robotic arm with four joints giving it 4° of movement a standard USB camera served as the robot's eye identifying the balls based on their color to ensure precise movement they first calculated the arms position using forward and inverse kinematics to sort the balls they corrected the camera's Distortion and processed the image to detect colors and positions once everything synced the robot seamlessly scanned grabbed and sorted the balls number 19 imagine walking past a booth at a maker fair and a robot suddenly locks eyes with you tracking your every move that's exactly what this Creator built a custom animatronic inspired by love death and robots featuring realistic eye movement and face detection the build started with a sculpted model cast in silicone molds with resin used for the final shell inside an Nvidia Jetson runs face detection allowing the robot's camera to track faces and adjust its gaze accordingly the eye mechanism is powered by eight servos individually controlling eye movement and blinking for added realism a Raspberry Pi 4 handles additional interactions using lidar to trigger sounds and lights when visitors get close while still a prototype the Creator plans to refine the tracking system to reduce overshooting and improve responsiveness if you ever see this robot don't be surprised if it stares right back at you number 18 koshiro has built a ball balancing robot that keeps a ball from ever falling off a glass plate but how does it work koshiro has explained the concept in detail but here's a simpler way to understand it beneath the plate there's a camera that captures the ball's position and image processing is used to track its coordinates an algorithm then checks how far the ball has deviated from the center and instructs the motors to move the ball back to that position this way the ball always stays on the platform number 17 let's look how the coders Cafe team is innovating to assist individuals with speech impairments in communicating more effectively they've developed a wearable device in the form of spectacles that can detect hand symbols and translate them into audible speech in real time the spectacle frame is 3D printed from pla filament while the design may not prioritize ergonomics it does have an appealing aesthetic a small pie camera is embedded at the center of the frame capturing hand gestures these gestures are then processed through a machine learning model which identifies the symbols and converts them into spoken words via a speaker this project is truly amazing offering a practical solution to a real life problem number 16 V projects has created a tiny device that alerts you when your boss is checking on you while you're busy playing games on your laptop it's like having an extra set of eyes watching your back the device uses a Raspberry Pi server and a detection kit the server is built with a pi 5 a Raspberry Pi AI kit and a camera module while the detection kit includes a pi pico2 a voltmeter a mosfet an LED and some resistors when the server detects someone in the frame it sends an alert to the detection kit the LED on the detector lights up and the dial moves towards one indicating a higher likelihood that someone is nearby number 15 this robot can detect and put out fires all on its own instead of relying on traditional fire sensors it uses image recognition with the Grove Vision AI module to spot flames in real time built with an Arduino Nano a Raspberry Pi camera module and a fan for extinguishing fires it runs on a trained AI model designed for accuracy to ensure the best performance two machine Lear learning models were tested one with sense craft Ai and another with Edge impulse after comparison The Edge impulse model proved to be the better choice the model was optimized to ensure it could run smoothly on the embedded system once deployed the robot can detect fire and activate the fan to put it out making it a useful safety tool number 14 recognizing vehicle number plates automatically can be useful for smart parking toll booths and security systems the hardware setup includes an ESP 32 an OLED display and a trigger button pressing the button captures an image and sends it to the Cloud Server via Wi-Fi the server processes the image extracts the license plate number and Returns the result to the esp32 which displays it on the screen during testing the system successfully identified multiple license plates but accuracy varied depending on lighting and font clarity while reliable in most cases certain characters like o and Q could be misread despite these minor limitations this project demonstrates an affordable and efficient way to integrate automated license plate recognition into real world applications before moving on to the next project a word from our sponsor Altium 365 is a powerful PCB design platform that makes it easy to share your design files with your team members can view edit and comment in realtime stre streamlining collaboration need input from a software engineer they'll get notified and can take action right away with easy access to data sheets and materials you can even send your design directly to the manufacturer simplifying the process and boosting workflow efficiency if you're a student looking to Kickstart your PCB design career Altium student lab offers online courses and free access to their cuttingedge design software to help you master the basics of PCB design and ecad fundamentals check the description for more details number 13 if you've ever wanted to build your own AI powered camera this project is a great place to start Eric designed a simple yet effective setup using an esp32 cam inside a cardboard box along with a push button to capture images and a screen to display them but how does it recognize objects here's how it works the ESP 32 cam captures an image and uploads it to a nodejs server which then calls the Google Vision API for image analysis once the object is identified the processed image is sent back to the ESP 32 cam providing detailed information about what it sees with this setup you can easily identify and analyze objects in real time number 12 meet auto bill a fast and effective setup to generate shopping bills thus reducing the checkout time this project might look like a product but it is completely DIY it identifies the objects using a camera placed above while the load cell at the bottom weighs the object the object along with its weight price and quantity is then automatically added to the cart and the bill is generated thus omitting the need for human involvement the users can simply pay the total amount and collect their groceries thus it reduces es the chances of forming long cues number 11 tired of standing over a trash bin second guessing where to toss that plastic wrapper the makers at Microsoft built a Raspberry Pi powered trash classifier that instantly tells you where an item belongs Landfill Recycling compost or hazardous waste using lobe a no code machine learning tool they trained a tensorflow model by feeding it images of different types of waste the model runs on a Raspberry Pi 4 which is housed in a custombuilt case with LED indicators and a push button to snap a photo once an item is scanned the system analyzes it and lights up the correct disposal bin no more guessing this project could make waste sorting way easier for everyone so would you build one number 10 manually sorting objects can be a tedious task but this project makes it effortless with automation here's how it works a Servo powered gripper picks up the objects and places them onto a conveyor belt as the belt moves an IR sensor detects an object and pauses the belt when it reaches the camera the captured image is then sent to a web browser where tensorflow light performs image classification once the object is identified the conveyor resumes movement and sorts the item accordingly making the entire process efficient and hands-free number nine with this project you can detect hands and fingers using Python and transform them into a gesture controlled virtual Mouse in this demo a webcam tracks hand movements demonstrating how image recognition works in real time moving your index finger controls the cursor in any direction while lowering your middle finger with the index finger still up acts as a click making interactions seamless and in itive to run this on an ESP 32 cam you only need to adjust the dimensions and frame rate in the code everything else Remains the Same ensuring smooth integration number eight running open CV on an ESP 32 cam is not that easy but by following this project you can do it esp32 cam captures the image and uses canny Edge detection with the open CV library in real time once the code runs the screen displays the ttgo demo for 3 seconds after that RGB mode grayscale mode binarized mode and Edge mode are executed repeatedly The canny Edge detection requires the most computational power hence the FPS of the displayed image is low but on average it displays the image with 6 FPS number seven with this project you'll learn how to build a QR code scanner using the esp32 cam module and open CV QR codes come in different versions based on the amount of data they store and this project allows you to decode even complex ones with ease to scan a QR code a python library is used to process the image frames captured by the es32 cam the code extracts these frames deciphers the QR code using a library function and then displays the decoded data on the screen in real time number six can a football game and become a high-tech interactive experience without breaking the bank mortaza set out to build a tic-tac-toe football wall not with expensive sensors but using computer vision and webcams traditional interactive football setups cost upwards of $133,000 due to specialized wall sensors instead this project uses two cameras a projector and AI detection to track ball hits One camera detects when the ball makes contact while while the second determines where it lands with yolo object detection a custom Tred model improves accuracy identifying ball hits in real time ensuring accurate ball tracking required fine-tuning the detection model and adjusting the cooldown time to prevent multiple detections per hit after 3 days of testing the system works with 70 to 90% accuracy making it perfect for casual play number five improper waste disposal is one of the concerning ways that is polluting the environment to address this issue octar decided to build a neural network-based robot that can classify different kinds of trash with the help of edge impulse it runs on Python scripts and can be operated remotely the laser scanner guides the robot around its environment thus avoiding obstacles as it travels around it captures images with the webcam which are classified by the neural network ensuring efficient sorting and Disposal number four counting some limited objects is easy but if the number is too large then you may definitely need some help for that this little project can be of great use to detect the object it uses a step-by-step method of image or frame conversion initially the RGB image is converted to grayscale so that the color contrast is visible and mathematical operations can be performed easily after that the image is blurred to blend the colors and using canny Edge detection the edges are detected finally to properly join the detected edges the image is dilated in this way the number of closed figures is detected and printed on the serial monitor number three what if you could play Minecraft without a keyboard or Mouse Gabriel built an AI power gesture control system that lets you move mine and interact all with hand movements the program runs on Google's media pipe AI which tracks hand landmarks and calculates distances between key points open CV helps estimate head size for scaling movements while a custom algorithm translates gestures into in-game actions instead of relying on traditional input methods the system uses multi-threading to process each action separately keeping gameplay smooth but there's a catch it's not perfect running requires rapid hand spasms crafting is a struggle and combat is really difficult still for a project that imagines how we interact with games it's an impressive feat number two you've probably seen this Eerie TV effect in horror movies the one where a ghost appears beside you on the screen but the moment you turn to look it vanishes spooky right but how does it actually work this illusion is brought to life using an old black and white TV hooked up to a Raspberry Pi 3 the trick lies in a small camera hidden inside the screen's headphone jack which captures the scene in front of the TV the footage is then processed through open CV running face and eye detection algorithms to track when someone is looking at the screen when the viewer looks away from the screen a ghostly figure suddenly appears lurking behind them but the moment they turn to check the Apparition vanishes just like in classic horror movie tropes it's a simple yet incredibly effective way to Spook anyone number one in this project you'll learn how to run depth AI on a Raspberry Pi using an oakd light camera enabling real-time object detection and spatial awareness this setup allows you to gather detailed information about an object's position in physical space to get started you'll need to install depth AI on the Raspberry Pi once the demo is running two screens will be displayed the left screen shows a color feed captured by the center lens providing a standard visual reference while the right screen presents a stereo depth View using both side lenses this depth screen displays an extended disparity map which helps calculate distances and create a 3D representation of the surroundings with this you can accurately detect objects and their positions in real time making it ideal for AI Vision applications if you've made it till here then drop a like And subscribe to our channel to keep supporting us comment the project that you loved the most we will be back with some great ideas soon till then goodbye\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5f63d26addd46e78dadc1e662263841"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0e3e003c2da4c88900ed8fdf21169c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ca0942a84024a6a8ca03fe3abc1a5d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73151843e78b41d0b6945829f71c2037"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'summary_text': \"number 13 if you've ever wanted to build your own AI powered camera this project is a great place to start Eric designed a simple yet effective setup using an esp32 cam inside a cardboard box along with a push button to capture images and a screen to display them but how does it recognize objects here's how it works the ESP 32 cam captures an image and uploads it to a nodejs server which then calls the Google Vision API for image analysis once the object is identified the processed image is sent back to the ESP 32 cam providing detailed information about what it sees with this setup you can easily identify and analyze objects in real time number 12 meet auto bill a fast and effective setup to generate shopping bills thus reducing the checkout time this project might look like a product but it is completely DIY it identifies the objects using a camera placed above while the load cell at the bottom weighs the object the object along with its weight price and quantity is then automatically added to the cart and the bill is generated thus omitting the need for human involvement the users can simply pay the total amount and collect their groceries thus it reduces es the chances\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(summary[0]['summary_text']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2dmvhY57Q1k",
        "outputId": "ccf0692b-6ca2-404f-f2d3-b902818b94db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vGSTRb6g9xTP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}